{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "\n",
    "# Assignment 2 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Desktop/CS3481- Fundamentals of Data Science/vertebral_column_data/column_3C.dat', sep=' ', header=None)\n",
    "data.columns = ['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric','degree_spondylolisthesis numeric','class']\n",
    "features = ['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric','degree_spondylolisthesis numeric']\n",
    "classes = ['disk hernia (DH)', 'spondylolisthesis (SL)', 'normal (NO)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:6].values\n",
    "Y=data.iloc[:,6].values\n",
    "#print (len(data))\n",
    "#print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=5)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817204301075269\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=10)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602150537634409\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=20)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602150537634409\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=30)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817204301075269\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=50)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8924731182795699\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=100)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "RFprediction = RFclf.predict(X_test)\n",
    "print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "\n",
    "# The best random forest is one with the most trees among all I tested. --> 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817204301075269\n"
     ]
    }
   ],
   "source": [
    "RFclf = RandomForestClassifier(n_estimators=100)\n",
    "RFclf = RFclf.fit(X_train, Y_train)\n",
    "print(RFclf.score(X_test,Y_test)) \n",
    "#RFprediction = RFclf.predict(X_test)\n",
    "#print(accuracy_score(Y_test, RFprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# 11th component tree\n",
    "DT1 = RFclf.estimators_[10]\n",
    "DT1 = DT1.fit(X_train,Y_train)\n",
    "print(DT1.score(X_test,Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8172043010752689\n"
     ]
    }
   ],
   "source": [
    "# 51th component tree\n",
    "DT2 = RFclf.estimators_[50]\n",
    "DT2 = DT2.fit(X_train,Y_train)\n",
    "print(DT2.score(X_test,Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956989247311828\n"
     ]
    }
   ],
   "source": [
    "# 91th component tree\n",
    "DT3 = RFclf.estimators_[90]\n",
    "DT3 = DT3.fit(X_train,Y_train)\n",
    "print(DT3.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 11th tree -> n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric', 'degree_spondylolisthesis numeric']\n",
      "[0.15054607 0.0223551  0.29845983 0.08816092 0.16113914 0.27933893]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(DT1.feature_importances_)    # the higher the value, the more important the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 51th tree -> n=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric', 'degree_spondylolisthesis numeric']\n",
      "[0.0620108  0.06386526 0.09143613 0.09266998 0.06607688 0.62394094]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(DT2.feature_importances_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 91th tree -> n=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric', 'degree_spondylolisthesis numeric']\n",
      "[0.30618497 0.11535975 0.07547124 0.0825032  0.19577095 0.22470989]\n"
     ]
    }
   ],
   "source": [
    "print(features)a\n",
    "print(DT3.feature_importances_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature important of the complete random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pelvic_incidence numeric', 'pelvic_tilt numeric', 'lumbar_lordosis_angle numeric', 'sacral_slope numeric', 'pelvic_radius numeric', 'degree_spondylolisthesis numeric']\n",
      "[0.1396279  0.09276069 0.11922486 0.11911471 0.12320436 0.40606747]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(RFclf.feature_importances_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclf = NBclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709677419354839\n"
     ]
    }
   ],
   "source": [
    "print(NBclf.score(X_test, Y_test))\n",
    "#NBprediction = NBclf.predict(X_test)\n",
    "#print(accuracy_score(Y_test, NBprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score returns --> no. of correct / total no. of samples, when normalize=True which is by default\n",
    "# so,that is same as when normalize=False and dividing the answer by no. of samples (len(data))\n",
    "# usually, every classifier has its own score method to implement its own performance metric, but in this case\n",
    "# it turns our that random forest's score method is also using accuracy_score method from the other library\n",
    "# what i have seen, for random forest, it uses accuracy_score itself in its .score method, the answer is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in (b) , we need to train the each individual tree / component tree of the random forest first. it will still\n",
    "# be the same way the random forest trained, as all the parameters are already set, such as max_features and \n",
    "# the random state, stating how the features subset is selected and how the data is randomized when training \n",
    "# the decision tree. So its paramets is set, and even in random forest, the different trees are just trained like \n",
    "# that and the mode of the classification is slected --> highest vote / the accuracy is averaged too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in (c), the naive bayes classifier is used by implementing it as the Gaussian naive bayes, because first of all, \n",
    "# we are usin naive bayes because it's a classification problem --> the target values/class labels are classes\n",
    "# --> categorical values, thus naive bayes is used because it's a classifier. Now, NB classifier can handle both\n",
    "# categorical data or continuous numeric data. It treats categorical data by getting the prior probability by \n",
    "# simpling counting, however for the numerica data, a distribution function is used --> The type of distribution\n",
    "# used is determined by the distribution existed in the type of the data in the dataset. Most likely, in everyday\n",
    "# cases, gaussian distribution can be good estimate so it's usually used for numeric continuous values. Hense, \n",
    "# we are using Gaussian Naive Bayes Classifer for our dataset in (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions? (unsolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What does random_state parameter does for decision tree algorithm? I understand for random forest. But where is\n",
    "# the randomness done in decision tree, and if not in features, as there is option to not choose subset first.\n",
    "\n",
    "# ANSWER --> I think i figured it out. The random_state for both decision tree and random forest is set to give \n",
    "# randomness to any part of the algorithm which requires it. If you set the specific seed, it can act as a way\n",
    "# to give deterministic / constant / same values no matter how many times you run the algorithm. This is good\n",
    "# for testing using same result. As in random forest, max_features is auto by default making the algorithm choose\n",
    "# a subset of features RANDOMLY before choosing the best from the subset. Also, as this algorithm chooses a subset\n",
    "# of training samples too, it's very likely the randomnesss is also applied to choosing the training samples first\n",
    "# before applying to the different component trees which are individual decision trees. Now, decision trees algorithm\n",
    "# by definition don't choose a subset of training samples first, so we can assume, as we can't know for sure how\n",
    "# the API / function is coded behind, that randomness is not applied here when applying the traning set to the model\n",
    "# however it could be applied to decision tree when its paramter max_feature is set to less than its maximum value\n",
    "# then randomness of choosing the subset will be applied. This is the most logical explanation by me so far. So\n",
    "# this means that, to train and test the individual trees of the forest, I need to randomly select a subset myself \n",
    "# too. So i can try this first!!! --> actually no way to know if randomness is applied in decision tree to the \n",
    "# training data --> so it remains the only question of this assigment --> ??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956989247311828\n"
     ]
    }
   ],
   "source": [
    "# 91th component tree\n",
    "DT3 = RFclf.estimators_[90]\n",
    "DT3 = DT3.fit(X_train,Y_train)\n",
    "print(DT3.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "DT3 = RFclf.estimators_[90]\n",
    "XTrain = np.zeros((len(X_train),len(features)))\n",
    "#YTrain = np.empty((len(Y_train),1), dtype=\"S10\")\n",
    "YTrain = [\"\" for yy in range(len(Y_train))]\n",
    "\n",
    "for i in range (0,len(X_train)):\n",
    "    row=randint(0,(len(X_train)-1))\n",
    "    XTrain[i]=X_train[row]\n",
    "    YTrain[i]=Y_train[row]\n",
    "\n",
    "DT3 = DT3.fit(XTrain,YTrain)\n",
    "print(DT3.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 77.69,  21.38,  64.43,  56.31, 114.82,  26.93],\n",
       "       [ 87.68,  20.37,  93.82,  67.31, 120.94,  76.73],\n",
       "       [ 46.44,   8.4 ,  29.04,  38.05, 115.48,   2.05],\n",
       "       ...,\n",
       "       [ 54.5 ,   6.82,  47.  ,  47.68, 111.79,  -4.41],\n",
       "       [ 38.05,   8.3 ,  26.24,  29.74, 123.8 ,   3.89],\n",
       "       [ 84.59,  30.36,  65.48,  54.22, 108.01,  25.12]])"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'DH',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'DH',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'SL',\n",
       " 'NO',\n",
       " 'NO',\n",
       " 'SL']"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
